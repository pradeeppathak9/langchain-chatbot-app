{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installing dependencies**"
      ],
      "metadata": {
        "id": "kKB_bhfOjH_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install langchain huggingface_hub openai tiktoken"
      ],
      "metadata": {
        "id": "Hmj6wPakpbXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading ENV!**"
      ],
      "metadata": {
        "id": "BJWALeM4i_zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Load environment variables from .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "Oovb7kwRTKXf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e9142a-d6f9-478f-f452-7410166c3181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **MEMORY**\n",
        "\n",
        "https://python.langchain.com/docs/modules/memory/"
      ],
      "metadata": {
        "id": "v9rsTTlhXrh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import HuggingFaceHub\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import VertexAI\n",
        "\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import (\n",
        "    ChatMessageHistory,\n",
        "    ConversationBufferMemory,\n",
        "    ConversationBufferWindowMemory,\n",
        "    ConversationEntityMemory,\n",
        "    ConversationKGMemory, # Conversation Knowledge Graph Memory\n",
        "    ConversationSummaryMemory, # Conversation summary memory\n",
        "    ConversationSummaryBufferMemory,\n",
        "    ConversationTokenBufferMemory,\n",
        ")"
      ],
      "metadata": {
        "id": "wWy62lRfTKZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# repo_id = \"tiiuae/falcon-7b-instruct\"\n",
        "# # repo_id = 'meta-llama/Llama-2-70b-chat-hf'\n",
        "# llm_falcon = HuggingFaceHub(\n",
        "#     huggingfacehub_api_token=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"],\n",
        "#     repo_id=repo_id,\n",
        "#     model_kwargs={\"temperature\":0.7, \"max_new_tokens\":500}\n",
        "# )\n",
        "\n",
        "# llm_openai = ChatOpenAI(\n",
        "#     openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "#     temperature=0.0)\n",
        "\n",
        "# llm_vertex = VertexAI(temperature=0.0)\n"
      ],
      "metadata": {
        "id": "6Tdj4DcZUMPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationBufferMemory / ConversationBufferWindowMemory**"
      ],
      "metadata": {
        "id": "v1m0eCm-4Aur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory()\n",
        "memory = ConversationBufferWindowMemory(k=0)\n",
        "\n",
        "# memory.save_context({\"input\": \"Hi\"}, {\"output\": \"What's up\"})\n",
        "# memory.load_memory_variables({})"
      ],
      "metadata": {
        "id": "1FJEzvn36TaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "w-5wLfmRXfRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi, there's a variable x = 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "jsmwH9EX3oVr",
        "outputId": "868cb576-6035-4ca7-f9ba-dedaae96e620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi, there's a variable x = 2\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello! It's nice to meet you. That's great to hear that there's a variable x with a value of 2. Is there anything specific you would like to know or discuss about this variable?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vsPngyYdo9JR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"there's another variable y=3\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "LnnGfny46S-g",
        "outputId": "8f37fdaf-9ce8-44dd-b60b-07d7adeaaf5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi, there's a variable x = 2\n",
            "AI: Hello! It's nice to meet you. That's great to hear that there's a variable x with a value of 2. Is there anything specific you would like to know or discuss about this variable?\n",
            "Human: there's another variable y=3\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"That's fantastic! It seems like you have another variable called y with a value of 3. It's great to see that you're working with multiple variables. Is there anything specific you would like to know or discuss about this variable y?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kb0jRHgMpEsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What's x*y\")"
      ],
      "metadata": {
        "id": "fj5zdnZUjmU1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "4e7f1b29-1495-48b5-8f17-adad472e1502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: there's another variable y=3\n",
            "AI: That's fantastic! It seems like you have another variable called y with a value of 3. It's great to see that you're working with multiple variables. Is there anything specific you would like to know or discuss about this variable y?\n",
            "Human: What's x*y\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"To find the product of x and y, we simply multiply the values of x and y together. Since you mentioned that y has a value of 3, we can multiply that by the value of x to get the result. However, I don't have any information about the value of x. Could you please provide the value of x so that I can calculate the product for you?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(memory.buffer)"
      ],
      "metadata": {
        "id": "iz0BHXzq4pD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPo38nU14pF8",
        "outputId": "1abf067a-4c4c-4903-c6ef-619f012e1112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': ''}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1mU9H_FM4pIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K7Q5Nb7ogMSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ConversationSummaryMemory / ConversationSummaryBufferMemory**"
      ],
      "metadata": {
        "id": "JdcjOKf4YBLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(temperature=0.0)\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "d6eSazxBYgnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a long string\n",
        "hist = \"\"\"\n",
        "The history of Berlin starts with its foundation in the 14th century. It became the capital of the Margraviate of Brandenburg in 1417, and later of Brandenburg-Prussia, and the Kingdom of Prussia. Prussia grew about rapidly in the 18th and 19th centuries and formed the basis of the German Empire in 1871. The empire would survive until 1918 when it was defeated in World War I.\n",
        "\n",
        "After 1900 Berlin became a major world city, known for its leadership roles in science, the humanities, music, museums, higher education, government, diplomacy and military affairs. It also had a role in manufacturing and finance.\n",
        "\n",
        "During World War II, bombing, artillery, and ferocious street-by-street fighting destroyed large parts of Berlin. Berlin was subsequently divided among the four major Allied powers and for over four decades it encapsulated the Cold War confrontation between West and East. With the reunification of Germany in 1990, Berlin was restored as the capital and as a major world city.\n",
        "\"\"\"\n",
        "\n",
        "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\n",
        "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
        "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
        "                    {\"output\": \"Cool\"})\n",
        "memory.save_context({\"input\": \"History of Berlin?\"},\n",
        "                    {\"output\": f\"{hist}\"})"
      ],
      "metadata": {
        "id": "gBOOv9cfWqDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErtkRpj6WqIY",
        "outputId": "19dba4a1-d4ee-4cbf-d930-67fa59c7a8ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"System: The human and AI engage in a casual conversation, discussing the history of Berlin. The AI provides a detailed overview of Berlin's history, from its foundation in the 14th century to its role as the capital of various entities, including the German Empire. It also highlights Berlin's significance in various fields such as science, humanities, music, and government. The conversation briefly touches upon the destruction caused during World War II and the division of Berlin during the Cold War. Finally, the AI mentions that Berlin was restored as the capital after the reunification of Germany in 1990.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "9XyB4y4UibeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What's Berlin importance in WW2?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "sWttgGzEYwiF",
        "outputId": "e7b29f8d-2e68-4f3e-a244-dac685de2adc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "System: The human and AI engage in a casual conversation, discussing the history of Berlin. The AI provides a detailed overview of Berlin's history, from its foundation in the 14th century to its role as the capital of various entities, including the German Empire. It also highlights Berlin's significance in various fields such as science, humanities, music, and government. The conversation briefly touches upon the destruction caused during World War II and the division of Berlin during the Cold War. Finally, the AI mentions that Berlin was restored as the capital after the reunification of Germany in 1990.\n",
            "Human: What's Berlin importance in WW2?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'During World War II, Berlin held great importance as the capital of Nazi Germany. Adolf Hitler, the leader of the Nazi Party, made Berlin the center of his regime and established various institutions and headquarters there. The city played a crucial role in the planning and execution of Nazi policies, including the persecution and extermination of millions of people during the Holocaust. Berlin was also heavily targeted by Allied bombings, resulting in significant destruction and loss of life. The Battle of Berlin in 1945 marked the final major offensive of the war in Europe, leading to the capture of the city by Soviet forces and the subsequent collapse of Nazi Germany.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory.load_memory_variables({})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wAJJq2NYwr5",
        "outputId": "6d0bf421-fd2d-4287-bc38-477b750fc80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'history': \"System: The human and AI engage in a casual conversation, discussing the history of Berlin. The AI provides a detailed overview of Berlin's history, from its foundation in the 14th century to its role as the capital of various entities, including the German Empire. It also highlights Berlin's significance in various fields such as science, humanities, music, and government. The conversation briefly touches upon the destruction caused during World War II and the division of Berlin during the Cold War. The AI mentions that Berlin was restored as the capital after the reunification of Germany in 1990. When asked about Berlin's importance in World War II, the AI explains that Berlin held great significance as the capital of Nazi Germany. Adolf Hitler made Berlin the center of his regime and it played a crucial role in the planning and execution of Nazi policies, including the Holocaust. Berlin was heavily targeted by Allied bombings and the Battle of Berlin in 1945 marked the final major offensive of the war in Europe. Soviet forces captured the city, leading to the collapse of Nazi Germany.\"}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KMdV7eI6ZaQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21OD9Qm8ZaS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7_Mxy3fXZaXR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zM70FZowGmgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZorN6qNTgAl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ogpuuKIjgnyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XOCu0vGhRgVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zibAKvALRsRU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}